{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ab1b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df2728b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descrimintor\n"
     ]
    }
   ],
   "source": [
    "def define_discriminator(in_shape=(28,28,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding=\"same\", input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "    opt = Adam(lr=0.0002,beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "print(\"Descrimintor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1e42f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator\n"
     ]
    }
   ],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_node = 128 *7 *7\n",
    "    model.add(Dense(n_node, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7,7,128)))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(1, (7,7), activation=\"sigmoid\", padding=\"same\"))\n",
    "    return model\n",
    "    \n",
    "    \n",
    "print(\"Generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f71732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n"
     ]
    }
   ],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model\n",
    "\n",
    "print(\"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1662c7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training\n"
     ]
    }
   ],
   "source": [
    "# load and prepare mnist training images\n",
    "def load_real_samples():\n",
    "    (trainX,_),(_,_) = load_data()\n",
    "    X = expand_dims(trainX, axis = -1)\n",
    "    X=X.astype('float32')\n",
    "    X=X/255.0\n",
    "    return X\n",
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples,1))\n",
    "    return X,y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim,n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(g_model,latent_dim,n_samples):\n",
    "    x_input = generate_latent_points(latent_dim,n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = zeros((n_samples,1))\n",
    "    return X,y\n",
    "\n",
    "# create and save a plot of generated images (reversed grayscale)\n",
    "def save_plot(examples, epoch, n=10):\n",
    "    for i in range(n * n):\n",
    "        pyplot.subplot(n,n,1+i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(examples[i,:,:,0], cmap='gray_r')\n",
    "    \n",
    "    filename = 'generated_plot_ep_%03d.png'%(epoch+1)\n",
    "    pyplot.savegif(filename)\n",
    "    pyplot.close()\n",
    "\n",
    "# evaluate the discriminator, plot generated images, save generator model\n",
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "    _, acc_real = d_model.evaluate(X_real,y_real, verbose=0)\n",
    "    X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    _, acc_fake = d_model.evaluate(X_fake, y_fake, verbose=0)\n",
    "\n",
    "    print(\"Accuracy real: %.0f%%, fake: %.0f%%\" % (acc_real*100, acc_fake*100))\n",
    "    save_plot(X_fake, epoch)\n",
    "\n",
    "    filename = 'generator_model_%03d.h5' %(epoch+1)\n",
    "    g_model.save(filename)\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"Before training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6244040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training\n"
     ]
    }
   ],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n",
    "    bat_per_epoch = int(dataset.shape[0]/n_batch)\n",
    "    half_batch = int(n_batch/2)\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epoch):\n",
    "\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            X,y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            d_loss,_ = d_model.train_on_batch(X,y)\n",
    "\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch,1))\n",
    "\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\n",
    "            print(\">epoch%d, %d/%d, d_loss=%.3f, g_loss=%.3f\" %(i+1,j+1,bat_per_epoch,d_loss,g_loss))\n",
    "        \n",
    "        if(i+1) % 10 ==10:\n",
    "            summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "print(\"After training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AL-MAKKAH\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 14s 1us/step\n",
      "4/4 [==============================] - 1s 84ms/step\n",
      "WARNING:tensorflow:From C:\\Users\\AL-MAKKAH\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AL-MAKKAH\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AL-MAKKAH\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AL-MAKKAH\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch1, 1/234, d_loss=0.708, g_loss=0.819\n",
      "4/4 [==============================] - 0s 81ms/step\n",
      ">epoch1, 2/234, d_loss=0.657, g_loss=0.930\n",
      "4/4 [==============================] - 0s 85ms/step\n",
      ">epoch1, 3/234, d_loss=0.640, g_loss=0.969\n",
      "4/4 [==============================] - 0s 82ms/step\n",
      ">epoch1, 4/234, d_loss=0.646, g_loss=0.877\n",
      "4/4 [==============================] - 0s 80ms/step\n",
      ">epoch1, 5/234, d_loss=0.662, g_loss=0.756\n",
      "4/4 [==============================] - 0s 79ms/step\n",
      ">epoch1, 6/234, d_loss=0.659, g_loss=0.697\n",
      "4/4 [==============================] - 0s 92ms/step\n",
      ">epoch1, 7/234, d_loss=0.623, g_loss=0.685\n",
      "4/4 [==============================] - 1s 106ms/step\n",
      ">epoch1, 8/234, d_loss=0.579, g_loss=0.689\n",
      "4/4 [==============================] - 0s 119ms/step\n",
      ">epoch1, 9/234, d_loss=0.536, g_loss=0.695\n",
      "4/4 [==============================] - 0s 86ms/step\n",
      ">epoch1, 10/234, d_loss=0.487, g_loss=0.701\n",
      "4/4 [==============================] - 0s 82ms/step\n",
      ">epoch1, 11/234, d_loss=0.444, g_loss=0.709\n",
      "4/4 [==============================] - 0s 86ms/step\n",
      ">epoch1, 12/234, d_loss=0.414, g_loss=0.717\n",
      "4/4 [==============================] - 0s 92ms/step\n",
      ">epoch1, 13/234, d_loss=0.384, g_loss=0.728\n",
      "4/4 [==============================] - 0s 72ms/step\n",
      ">epoch1, 14/234, d_loss=0.369, g_loss=0.744\n",
      "4/4 [==============================] - 0s 80ms/step\n",
      ">epoch1, 15/234, d_loss=0.348, g_loss=0.765\n",
      "4/4 [==============================] - 0s 76ms/step\n",
      ">epoch1, 16/234, d_loss=0.331, g_loss=0.795\n",
      "4/4 [==============================] - 0s 113ms/step\n",
      ">epoch1, 17/234, d_loss=0.317, g_loss=0.835\n",
      "4/4 [==============================] - 1s 128ms/step\n",
      ">epoch1, 18/234, d_loss=0.298, g_loss=0.893\n",
      "4/4 [==============================] - 0s 89ms/step\n",
      ">epoch1, 19/234, d_loss=0.275, g_loss=0.971\n",
      "4/4 [==============================] - 0s 104ms/step\n",
      ">epoch1, 20/234, d_loss=0.250, g_loss=1.075\n",
      "4/4 [==============================] - 1s 115ms/step\n",
      ">epoch1, 21/234, d_loss=0.219, g_loss=1.223\n",
      "4/4 [==============================] - 0s 95ms/step\n",
      ">epoch1, 22/234, d_loss=0.191, g_loss=1.412\n",
      "4/4 [==============================] - 0s 94ms/step\n",
      ">epoch1, 23/234, d_loss=0.150, g_loss=1.657\n",
      "4/4 [==============================] - 0s 98ms/step\n",
      ">epoch1, 24/234, d_loss=0.115, g_loss=1.925\n",
      "4/4 [==============================] - 0s 95ms/step\n",
      ">epoch1, 25/234, d_loss=0.089, g_loss=2.237\n",
      "4/4 [==============================] - 0s 77ms/step\n",
      ">epoch1, 26/234, d_loss=0.070, g_loss=2.528\n",
      "4/4 [==============================] - 0s 78ms/step\n",
      ">epoch1, 27/234, d_loss=0.062, g_loss=2.798\n",
      "4/4 [==============================] - 0s 78ms/step\n",
      ">epoch1, 28/234, d_loss=0.045, g_loss=3.023\n",
      "4/4 [==============================] - 0s 86ms/step\n",
      ">epoch1, 29/234, d_loss=0.039, g_loss=3.226\n",
      "4/4 [==============================] - 0s 81ms/step\n",
      ">epoch1, 30/234, d_loss=0.032, g_loss=3.369\n",
      "4/4 [==============================] - 0s 105ms/step\n",
      ">epoch1, 31/234, d_loss=0.027, g_loss=3.519\n",
      "4/4 [==============================] - 0s 84ms/step\n",
      ">epoch1, 32/234, d_loss=0.024, g_loss=3.644\n",
      "4/4 [==============================] - 0s 86ms/step\n",
      ">epoch1, 33/234, d_loss=0.017, g_loss=3.786\n",
      "4/4 [==============================] - 0s 85ms/step\n",
      ">epoch1, 34/234, d_loss=0.014, g_loss=3.946\n",
      "4/4 [==============================] - 0s 88ms/step\n",
      ">epoch1, 35/234, d_loss=0.018, g_loss=4.038\n",
      "4/4 [==============================] - 0s 87ms/step\n",
      ">epoch1, 36/234, d_loss=0.012, g_loss=4.126\n",
      "4/4 [==============================] - 0s 88ms/step\n",
      ">epoch1, 37/234, d_loss=0.022, g_loss=3.981\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 38/234, d_loss=3.457, g_loss=0.726\n",
      "4/4 [==============================] - 0s 84ms/step\n",
      ">epoch1, 39/234, d_loss=7.443, g_loss=0.341\n",
      "4/4 [==============================] - 0s 92ms/step\n",
      ">epoch1, 40/234, d_loss=1.303, g_loss=9.544\n",
      "4/4 [==============================] - 0s 90ms/step\n",
      ">epoch1, 41/234, d_loss=1.416, g_loss=9.842\n",
      "4/4 [==============================] - 0s 92ms/step\n",
      ">epoch1, 42/234, d_loss=1.274, g_loss=6.136\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 43/234, d_loss=0.764, g_loss=3.047\n",
      "4/4 [==============================] - 0s 88ms/step\n",
      ">epoch1, 44/234, d_loss=0.409, g_loss=2.035\n",
      "4/4 [==============================] - 0s 90ms/step\n",
      ">epoch1, 45/234, d_loss=0.365, g_loss=1.647\n",
      "4/4 [==============================] - 0s 90ms/step\n",
      ">epoch1, 46/234, d_loss=0.401, g_loss=1.388\n",
      "4/4 [==============================] - 0s 103ms/step\n",
      ">epoch1, 47/234, d_loss=0.594, g_loss=1.421\n",
      "4/4 [==============================] - 0s 88ms/step\n",
      ">epoch1, 48/234, d_loss=0.468, g_loss=1.372\n",
      "4/4 [==============================] - 0s 89ms/step\n",
      ">epoch1, 49/234, d_loss=0.516, g_loss=1.471\n",
      "4/4 [==============================] - 0s 94ms/step\n",
      ">epoch1, 50/234, d_loss=0.705, g_loss=1.428\n",
      "4/4 [==============================] - 0s 85ms/step\n",
      ">epoch1, 51/234, d_loss=0.618, g_loss=1.483\n",
      "4/4 [==============================] - 0s 85ms/step\n",
      ">epoch1, 52/234, d_loss=0.563, g_loss=1.505\n",
      "4/4 [==============================] - 0s 87ms/step\n",
      ">epoch1, 53/234, d_loss=0.605, g_loss=1.486\n",
      "4/4 [==============================] - 0s 84ms/step\n",
      ">epoch1, 54/234, d_loss=0.668, g_loss=1.385\n",
      "4/4 [==============================] - 0s 86ms/step\n",
      ">epoch1, 55/234, d_loss=0.593, g_loss=1.551\n",
      "4/4 [==============================] - 0s 85ms/step\n",
      ">epoch1, 56/234, d_loss=0.681, g_loss=1.421\n",
      "4/4 [==============================] - 0s 85ms/step\n",
      ">epoch1, 57/234, d_loss=0.783, g_loss=1.348\n",
      "4/4 [==============================] - 0s 86ms/step\n",
      ">epoch1, 58/234, d_loss=0.741, g_loss=1.514\n",
      "4/4 [==============================] - 0s 89ms/step\n",
      ">epoch1, 59/234, d_loss=0.706, g_loss=1.485\n",
      "4/4 [==============================] - 0s 104ms/step\n",
      ">epoch1, 60/234, d_loss=0.699, g_loss=1.254\n",
      "4/4 [==============================] - 0s 84ms/step\n",
      ">epoch1, 61/234, d_loss=0.686, g_loss=1.147\n",
      "4/4 [==============================] - 0s 89ms/step\n",
      ">epoch1, 62/234, d_loss=0.703, g_loss=1.060\n",
      "4/4 [==============================] - 0s 96ms/step\n",
      ">epoch1, 63/234, d_loss=0.684, g_loss=1.081\n",
      "4/4 [==============================] - 0s 89ms/step\n",
      ">epoch1, 64/234, d_loss=0.682, g_loss=1.088\n",
      "4/4 [==============================] - 0s 84ms/step\n",
      ">epoch1, 65/234, d_loss=0.681, g_loss=1.128\n",
      "4/4 [==============================] - 0s 87ms/step\n",
      ">epoch1, 66/234, d_loss=0.675, g_loss=1.109\n",
      "4/4 [==============================] - 0s 101ms/step\n",
      ">epoch1, 67/234, d_loss=0.703, g_loss=1.079\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 68/234, d_loss=0.659, g_loss=1.068\n",
      "4/4 [==============================] - 0s 103ms/step\n",
      ">epoch1, 69/234, d_loss=0.642, g_loss=0.982\n",
      "4/4 [==============================] - 0s 94ms/step\n",
      ">epoch1, 70/234, d_loss=0.632, g_loss=0.986\n",
      "4/4 [==============================] - 0s 87ms/step\n",
      ">epoch1, 71/234, d_loss=0.639, g_loss=0.927\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 72/234, d_loss=0.640, g_loss=0.964\n",
      "4/4 [==============================] - 0s 90ms/step\n",
      ">epoch1, 73/234, d_loss=0.652, g_loss=0.957\n",
      "4/4 [==============================] - 0s 100ms/step\n",
      ">epoch1, 74/234, d_loss=0.642, g_loss=0.954\n",
      "4/4 [==============================] - 0s 94ms/step\n",
      ">epoch1, 75/234, d_loss=0.624, g_loss=0.946\n",
      "4/4 [==============================] - 0s 92ms/step\n",
      ">epoch1, 76/234, d_loss=0.629, g_loss=0.990\n",
      "4/4 [==============================] - 0s 95ms/step\n",
      ">epoch1, 77/234, d_loss=0.627, g_loss=0.944\n",
      "4/4 [==============================] - 0s 93ms/step\n",
      ">epoch1, 78/234, d_loss=0.646, g_loss=0.962\n",
      "4/4 [==============================] - 0s 92ms/step\n",
      ">epoch1, 79/234, d_loss=0.631, g_loss=0.953\n",
      "4/4 [==============================] - 0s 93ms/step\n",
      ">epoch1, 80/234, d_loss=0.667, g_loss=0.965\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 81/234, d_loss=0.585, g_loss=0.941\n",
      "4/4 [==============================] - 0s 93ms/step\n",
      ">epoch1, 82/234, d_loss=0.620, g_loss=0.893\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 83/234, d_loss=0.574, g_loss=0.914\n",
      "4/4 [==============================] - 0s 93ms/step\n",
      ">epoch1, 84/234, d_loss=0.589, g_loss=0.946\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 85/234, d_loss=0.590, g_loss=0.902\n",
      "4/4 [==============================] - 0s 99ms/step\n",
      ">epoch1, 86/234, d_loss=0.562, g_loss=0.903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 96ms/step\n",
      ">epoch1, 87/234, d_loss=0.589, g_loss=0.903\n",
      "4/4 [==============================] - 0s 99ms/step\n",
      ">epoch1, 88/234, d_loss=0.593, g_loss=1.034\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 89/234, d_loss=0.571, g_loss=0.999\n",
      "4/4 [==============================] - 0s 94ms/step\n",
      ">epoch1, 90/234, d_loss=0.571, g_loss=0.972\n",
      "4/4 [==============================] - 0s 98ms/step\n",
      ">epoch1, 91/234, d_loss=0.574, g_loss=1.059\n",
      "4/4 [==============================] - 0s 100ms/step\n",
      ">epoch1, 92/234, d_loss=0.562, g_loss=0.985\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 93/234, d_loss=0.575, g_loss=0.986\n",
      "4/4 [==============================] - 0s 104ms/step\n",
      ">epoch1, 94/234, d_loss=0.534, g_loss=0.996\n",
      "4/4 [==============================] - 0s 93ms/step\n",
      ">epoch1, 95/234, d_loss=0.544, g_loss=0.987\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 96/234, d_loss=0.526, g_loss=1.035\n",
      "4/4 [==============================] - 0s 90ms/step\n",
      ">epoch1, 97/234, d_loss=0.510, g_loss=1.069\n",
      "4/4 [==============================] - 0s 96ms/step\n",
      ">epoch1, 98/234, d_loss=0.536, g_loss=1.118\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 99/234, d_loss=0.509, g_loss=1.093\n",
      "4/4 [==============================] - 0s 88ms/step\n",
      ">epoch1, 100/234, d_loss=0.481, g_loss=1.078\n",
      "4/4 [==============================] - 0s 103ms/step\n",
      ">epoch1, 101/234, d_loss=0.473, g_loss=1.044\n",
      "4/4 [==============================] - 0s 91ms/step\n",
      ">epoch1, 102/234, d_loss=0.495, g_loss=1.091\n",
      "4/4 [==============================] - 0s 97ms/step\n",
      ">epoch1, 103/234, d_loss=0.484, g_loss=1.070\n",
      "4/4 [==============================] - 0s 93ms/step\n",
      ">epoch1, 104/234, d_loss=0.510, g_loss=1.105\n",
      "4/4 [==============================] - 0s 112ms/step\n",
      ">epoch1, 105/234, d_loss=0.475, g_loss=1.094\n",
      "4/4 [==============================] - 0s 92ms/step\n",
      ">epoch1, 106/234, d_loss=0.471, g_loss=1.171\n",
      "4/4 [==============================] - 0s 96ms/step\n",
      ">epoch1, 107/234, d_loss=0.478, g_loss=1.214\n",
      "4/4 [==============================] - 0s 93ms/step\n",
      ">epoch1, 108/234, d_loss=0.452, g_loss=1.213\n",
      "4/4 [==============================] - 0s 112ms/step\n",
      ">epoch1, 109/234, d_loss=0.479, g_loss=1.153\n",
      "4/4 [==============================] - 0s 115ms/step\n",
      ">epoch1, 110/234, d_loss=0.472, g_loss=1.157\n",
      "4/4 [==============================] - 0s 103ms/step\n",
      ">epoch1, 111/234, d_loss=0.481, g_loss=1.171\n",
      "4/4 [==============================] - 0s 101ms/step\n",
      ">epoch1, 112/234, d_loss=0.458, g_loss=1.178\n",
      "4/4 [==============================] - 0s 100ms/step\n",
      ">epoch1, 113/234, d_loss=0.452, g_loss=1.252\n",
      "4/4 [==============================] - 0s 108ms/step\n",
      ">epoch1, 114/234, d_loss=0.467, g_loss=1.166\n",
      "4/4 [==============================] - 0s 100ms/step\n",
      ">epoch1, 115/234, d_loss=0.461, g_loss=1.153\n",
      "4/4 [==============================] - 0s 95ms/step\n",
      ">epoch1, 116/234, d_loss=0.476, g_loss=1.119\n",
      "4/4 [==============================] - 0s 95ms/step\n",
      ">epoch1, 117/234, d_loss=0.447, g_loss=1.065\n",
      "4/4 [==============================] - 0s 95ms/step\n",
      ">epoch1, 118/234, d_loss=0.455, g_loss=1.096\n",
      "4/4 [==============================] - 0s 100ms/step\n",
      ">epoch1, 119/234, d_loss=0.485, g_loss=1.202\n",
      "4/4 [==============================] - 0s 96ms/step\n",
      ">epoch1, 120/234, d_loss=0.508, g_loss=1.184\n",
      "4/4 [==============================] - 0s 111ms/step\n",
      ">epoch1, 121/234, d_loss=0.548, g_loss=1.195\n",
      "4/4 [==============================] - 0s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "dataset = load_real_samples()\n",
    "\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76277f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
